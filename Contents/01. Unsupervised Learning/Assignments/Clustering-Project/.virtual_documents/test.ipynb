


# Data Manipulation
import numpy as np
import pandas as pd

# Visualization and Image Processing
import matplotlib.pyplot as plt
import seaborn as sns
import cv2

# Machine Learning
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

# for loading/processing the images  
from keras.utils import load_img
from keras.utils import img_to_array
from keras.applications.vgg16 import preprocess_input 
# models 
from keras.applications.vgg16 import VGG16 
from keras.models import Model

# Others
import os 
import random





BASE_DIR_ORL = "./ORL/"


def read_images(base_dir:str=BASE_DIR_ORL):
    images = []
    labels = []
    for file_name in os.listdir(BASE_DIR_ORL):
        try:
            image = cv2.imread(os.path.join(BASE_DIR_ORL, file_name))
            # Convert it from BGR to RGB so we can plot them later (because openCV reads images as BGR)
            #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            label = file_name.split('_')[1].split('.')[0]
            
            if image is not None:
                images.append(image)
                labels.append(label)
                
            else:
                print(f"Image {file_name} is None!")
        
        except Exception as e:
            print(f"Error: {e}")

    return images, labels
           





images, labels = read_images()


images[0].shape


pixel_features = np.array([image.flatten() for image in images])


def show_random_images(images, labels, num=2):
    sorted_labels = list(map(int, set(labels)))
    sorted_labels.sort()
    for code in sorted_labels:
        indicies = [i for i, label in enumerate(labels) if label == str(code)]
        random_indicies = [random.choice(indicies) for i in range(num)]
        figure, axis = plt.subplots(1, num)

        print("{} random images for code {}".format(num, code))

        for image in range(num):
            axis[image].imshow(images[random_indicies[image]])
        plt.show()
    


show_random_images(images, labels, num=2)








from sklearn.manifold import TSNE
X = pixel_features
y = labels
X_embedded = TSNE(n_components=2, learning_rate='auto',
                  init='random', perplexity=3, ).fit_transform(X)


# Create a colormap for distinct colors for each class
num_classes = len(np.unique(labels))
colors = plt.cm.jet(np.linspace(0, 1, num_classes))


plt.figure(figsize=(10, 10))
plt.xlim(X_embedded[:, 0].min(), X_embedded[:, 0].max()+1)
plt.ylim(X_embedded[:, 1].min(), X_embedded[:, 1].max()+1)
for i in range(len(labels)):
    if labels[i] == '17':
        plt.text(X_embedded[i, 0], X_embedded[i, 1], labels[i], color=colors[int(labels[i])-1], fontdict={'weight': 'bold', 'size' : 9})
plt.show()





from sklearn.cluster import KMeans


# Cluster the data using k-means
kmeans = KMeans(n_clusters=41, random_state=42)
labels_pred_kmeans = kmeans.fit_predict(X)
labels_pred_kmeans = labels_pred_kmeans +1





from sklearn.metrics.cluster import rand_score
rand_score(list(map(int, labels)), labels_pred_kmeans)


# Create a colormap for distinct colors for each class
num_classes = len(np.unique(labels_pred_kmeans))
colors1 = plt.cm.jet(np.linspace(0, 1, num_classes))


plt.figure(figsize=(10, 10))
plt.xlim(X_embeded[:, 0].min(), X_embeded[:0].max())
plt.ylim(X_embeded[:, 1].min(), X_embeded[:1].max())
plt.scatter()














os.getcwd()


BASE_DIR = './lfw/'
BASE_DIR_10 = './lfw_10/'


list_of_dirs = []
for dir in os.listdir(BASE_DIR):
    #print(os.listdir(os.path.join(BASE_DIR, dir)))
    length = len(os.listdir(os.path.join(BASE_DIR, dir)))
    list_of_dirs.append((dir, length))


def func(param):
    return param[1]


list_of_dirs.sort(key=func, reverse=True)  


selected_dirs = [ name [0] for name in list_of_dirs[:10]]


import shutil
for dir in os.listdir(BASE_DIR_10):
    if dir not in selected_dirs:
        shutil.rmtree(os.path.join(BASE_DIR_10, dir))





images_path = []
for dir in os.listdir(BASE_DIR_10):
    new_dir = os.path.join(BASE_DIR_10, dir)
    for file in os.listdir(new_dir):
        images_path.append(os.path.join(new_dir, file))


# load the model first and pass as an argument
model = VGG16()
model = Model(inputs = model.inputs, outputs = model.layers[-2].output)

def extract_features(file, model):
    #name = ' '.join(file.split('/')[-1].split('.')[0].split('_')[:2])
    name = int(file.split('/')[-1].split('.')[0].split('_')[-1])
    # load the image as a 224x224 array
    img = load_img(file, target_size=(224,224))
    # convert from 'PIL.Image.Image' to numpy array
    img = np.array(img) 
    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)
    reshaped_img = img.reshape(1,224,224,3) 
    # prepare image for model
    imgx = preprocess_input(reshaped_img)
    # get the feature vector
    features = model.predict(imgx, use_multiprocessing=True)
    
    # Flatten the features to a 1D array
    features = features.flatten()


    return features, name


images_path = []
for file in os.listdir(BASE_DIR_ORL):
    new_dir = os.path.join(BASE_DIR_ORL, file)
    images_path.append(new_dir)


features = []
labels = []

# lop through each image in the dataset
for path in images_path:
    # try to extract the features and update the dictionary
    feat, name = extract_features(path,model)
    features.append(feat)
    labels.append(name)


plt.imshow(features[0].reshape(64, -1))


unique_names = set(labels)
name_to_id = {name: i+1 for i, name in enumerate(unique_names)}
id_list = [name_to_id[name] for name in labels]


from sklearn.manifold import TSNE
X = np.array(features)
y = labels
X_embedded = TSNE(n_components=2, learning_rate='auto',
                  init='random', perplexity=45, ).fit_transform(X)


# Create a colormap for distinct colors for each class
num_classes = len(np.unique(labels))
colors = plt.cm.jet(np.linspace(0, 1, num_classes))


plt.figure(figsize=(10, 10))
plt.xlim(X_embedded[:, 0].min(), X_embedded[:, 0].max()+1)
plt.ylim(X_embedded[:, 1].min(), X_embedded[:, 1].max()+1)
for i in range(len(y)):
    #if y[i] == 1 :
        plt.text(X_embedded[i, 0], X_embedded[i, 1], y[i], color=colors[int(y[i])-1], fontdict={'weight': 'bold', 'size' : 9})
plt.show()


# Cluster the data using k-means
kmeans = KMeans(n_clusters=41, random_state=42)
labels_pred_kmeans = kmeans.fit_predict(X)


from sklearn.metrics.cluster import rand_score
rand_score(list(map(int, y)), labels_pred_kmeans)


from sklearn.cluster import DBSCAN
dbscan = DBSCAN(eps=1000, min_samples=4, n_jobs=-1)
labels_pred_dbscan = dbscan.fit_predict(X)


from sklearn.metrics.cluster import rand_score
rand_score(list(map(int, y)), labels_pred_dbscan)



